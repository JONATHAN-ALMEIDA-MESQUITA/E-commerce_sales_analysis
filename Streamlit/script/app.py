#Importando as principais bibliotecas
import streamlit as st
import pandas as pd
import numpy as np
import matplotlib
import seaborn as sns
import matplotlib.pyplot as plt
import joblib
import plotly.express as px
import plotly.graph_objects as go
import plotly.subplots as sp

#Bibliotecas para analise de regress√£o linear
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression
from xgboost import XGBRegressor
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score



# Estrutura de dados





#Estrutura do APP
# T√≠tulo da aplica√ß√£o
st.title('üìà An√°lise de Vendas de Com√©rcio Eletr√¥nico')

# Informa√ß√µes gerais sobre o DataFrame
st.subheader('Informa√ß√µes sobre o DataFrame')

st.markdown(''' ###### Conjunto de dados abrangendo uma variedade de categorias de produtos de um E-comerce, pre√ßos, avalia√ß√µes de clientes e tend√™ncias de vendas no √∫ltimo ano. 
###### Este conjunto de dados √© ideal para analisar tend√™ncias de mercado, comportamento do cliente e desempenho de vendas. 
Vamos explorar os dados para descobrir insights que podem otimizar listagens de precos de produtos, estrat√©gias de campanhas de marketing e previs√£o de vendas!
''')

# Leitura do DataFrame
@st.cache_data
def load_data():
    df = pd.read_csv('data/ecommerce_sales_analysis_input.csv')

    return df

df = load_data()

# Exibi√ß√£o inicial do DataFrame
if st.checkbox('Mostrar dados'):
    st.write(df)



# Estat√≠sticas descritivas
st.subheader('Estat√≠sticas Descritivas')
st.write(df.describe())

st.markdown(''' ### Interpreta√ß√£o:

1. count: Todas as colunas t√™m 1000 registros. Isso indica que n√£o h√° valores ausentes nos dados.

2. mean (m√©dia):
O pre√ßo m√©dio dos produtos (price) √© 247,67.
A pontua√ß√£o m√©dia das avalia√ß√µes (review_score) √© 3,03 o que sugere que, em m√©dia, os produtos t√™m uma avalia√ß√£o satisfat√≥ria.
As vendas m√©dias por m√™s variam entre 487,19 e 514,80, mostrando uma certa consist√™ncia nas vendas ao longo dos meses.


3. std (desvio padr√£o):
O desvio padr√£o do pre√ßo (price) √© 144,61, indicando que h√° uma grande varia√ß√£o nos pre√ßos dos produtos. Esse desvio representa 58% do valor medio do produto gerando uma grande dispe√ß√£o nos pre√ßos.

4. A pontua√ß√£o de avalia√ß√£o tem um desvio padr√£o de 1,17, sugerindo alguma dispers√£o nas avalia√ß√µes dos produtos.
As vendas mensais t√™m desvios padr√£o em torno de 280-290, o que pode indicar que h√° varia√ß√µes consider√°veis nas vendas mensais entre os produtos.
''')


# Feature Engineering
df['mean_sales'] = df[[f'sales_month_{i}' for i in range(1, 13)]].mean(axis=1)
df['variance_sales'] = df[[f'sales_month_{i}' for i in range(1, 13)]].var(axis=1)
df['price_to_category_mean'] = df['price'] / df.groupby('category')['price'].transform('mean')
df['quantity_total_sold'] = df[[f'sales_month_{i}' for i in range(1, 13)]].sum(axis=1)
df['amount_total_sold'] = df['quantity_total_sold'] * df['price']
df['log_price'] = np.log1p(df['price'])
df['log_total_sales'] = np.log1p(df['amount_total_sold'])
df['price_range'] = pd.cut(df['price'], bins=[0, 100, 300, np.inf], labels=['Low', 'Medium', 'High'])
df['peak_month'] = df[[f'sales_month_{i}' for i in range(1, 13)]].idxmax(axis=1).str.extract(r'(\d+)').astype(int)
df['price_review_interaction'] = df['price'] * df['review_score']

# Visualiza√ß√£o 1: Boxplot de vendas m√©dias por categoria
st.subheader('Vendas M√©dias por Categoria')
fig1 = px.box(df, x='category', y='mean_sales', title='Boxplot analise de vendas')
fig1.update_xaxes(tickangle=45)  # Rotaciona os r√≥tulos do eixo x
st.plotly_chart(fig1)

st.markdown('''##### Conclus√£o boxplot
As categorias apresentam distribui√ß√µes de vendas relativamente equilibradas, exceto Books, que mostra maior variabilidade e Electronics, que tem outliers indicando vendas pontuais altas.
Pode ser interessante investigar mais a fundo os outliers em Electronics para entender o que impulsionou as vendas nesses casos.
''')

# Visualiza√ß√£o 2: Contagem de Produtos por Faixa de Pre√ßo
st.subheader('Contagem de Produtos por Faixa de Pre√ßo')
fig2 = px.histogram(df, x='price_range', title='Distribui√ß√£o faixa de pre√ßo')
fig2.update_layout(xaxis_title='Faixa de Pre√ßo', yaxis_title='Contagem')
st.plotly_chart(fig2)

st.markdown('''##### Interpreta√ß√£o dos Padr√µes:

+ Distribui√ß√£o da faixa de pre√ßo: Este grafico apenas confirma a analise de distribui√ß√£o de valores, 
porem sem a plica√ß√£o logar√≠tmica nos pre√ßos, o que mostra consist√™ncia na conclus√£o da analise do conjuntos de graficos no 
'profile.html' onde conseguimos ver a adistribui√ß√£o no log_total_sales e log_price. A distribui√ß√£o do volume de produtos e valor est√£o 
classificados entre valores medios e altos em rela√ß√£o a todo volume de produtos, ou seja possuimos uma grande quantidade de produtos com preco medio e alta em rela√ß√£o a todos os produtos do e-comerce.

''')

# Analise de sazonalidade'
st.subheader('M√™s de Pico de Vendas por Produto')
fig = px.histogram(df, x='peak_month', nbins=12, title='Analise sazonalidade')# Criando o gr√°fico interativo com Plotly
fig.update_layout(
    xaxis_title='M√™s',
    yaxis_title='Contagem de Produtos',
    bargap=0.2
) #Adicionando r√≥tulos e layout

# Exibindo o gr√°fico no Streamlit
st.plotly_chart(fig)

st.markdown('''##### Analise sazonalidade

Interpreta√ß√£o:

+ M√™s 7 (Julho): √â claramente o m√™s com o maior n√∫mero de produtos atingindo seu pico de vendas. Isso pode indicar uma forte demanda sazonal, possivelmente devido a promo√ß√µes de meio de ano ou f√©rias.

+ Demais Meses: H√° uma distribui√ß√£o relativamente uniforme para os outros meses, com exce√ß√£o do m√™s 12 (Dezembro), que tem a menor contagem de produtos atingindo o pico de vendas. Isso pode ser um indicativo de que alguns produtos n√£o t√™m um aumento significativo de vendas durante o per√≠odo natalino.
''')


# Visualiza√ß√£o 4: Mapa de Calor - Categorias por M√™s de Pico de Vendas
# Criando a tabela cruzada
category_peak_month = pd.crosstab(df['peak_month'], df['category'])

# Criando a figura do heatmap
fig_heatmap = go.Figure(data=go.Heatmap(
    z=category_peak_month.values,
    x=category_peak_month.columns,
    y=category_peak_month.index,
    colorscale='Blues',
    colorbar=dict(title='Contagem'),
    text=category_peak_month.values,
    texttemplate='%{text}',  # Formato para mostrar os n√∫meros
    textfont=dict(size=12, color='white')
))

fig_heatmap.update_layout(
    title='Categorias de Produtos por M√™s de Pico de Vendas',
    xaxis_title='Categoria',
    yaxis_title='M√™s de Pico'
)

st.plotly_chart(fig_heatmap)

st.markdown('''##### Interpreta√ß√£o dos Padr√µes:

+ Com o mapa de calor conseguimos entender quais foram as categorias mais vendidades durantes os meses, √© notavel a quantidade de vendas de eletronicos no mes 7 (Julho) o que impactou significativamente nas vendas do m√™s, devido a alta correla√ß√£o. O mesmo impcto em eletetronicos ocorreu em Dezembro, porem o impacto foi o contrario do m√™s de Julho.
''')




# Visualiza√ß√£o 5: Intera√ß√£o entre Pre√ßo e Avalia√ß√£o
# Criando o scatter plot interativo
fig_scatter = px.scatter(df, x='price', y='price_review_interaction',
                        color='review_score', color_continuous_scale='viridis',
                        title='Intera√ß√£o entre Pre√ßo e Avalia√ß√£o',
                        labels={'price': 'Pre√ßo', 'price_review_interaction': 'Intera√ß√£o Pre√ßo x Avalia√ß√£o'})

fig_scatter.update_layout(coloraxis_colorbar=dict(title='Pontua√ß√£o de Avalia√ß√£o'))
st.plotly_chart(fig_scatter)

st.markdown('''##### Interpreta√ß√£o dos Padr√µes:

O gr√°fico mostra a rela√ß√£o entre o pre√ßo e a avalia√ß√£o de um produto. O eixo x representa o pre√ßo do produto, e o eixo y representa a avalia√ß√£o m√©dia do produto. A linha no gr√°fico mostra a tend√™ncia geral da rela√ß√£o entre o pre√ßo e a avalia√ß√£o.

No geral, o gr√°fico mostra que h√° uma correla√ß√£o positiva entre o pre√ßo e a avalia√ß√£o do produto. Isso significa que, em geral, produtos com pre√ßos mais altos tendem a ter avalia√ß√µes mais altas.


''')




# modelagem de dados:

# Aplicando One-Hot Encoding para as colunas 'category' e 'price_range'
df = pd.get_dummies(df, columns=['category', 'price_range'], prefix=['cat', 'price_range'])

# Definindo as vari√°veis independentes (X) e a vari√°vel dependente (y)
X = df.drop(columns=['amount_total_sold', 'product_name'])  # Excluindo colunas irrelevantes
y = df['amount_total_sold']  # Vari√°vel que desejamos prever

# Dividindo os dados em treino e teste
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)



# Instanciando o modelo
rf_model = RandomForestRegressor(random_state=42)

# Treinando o modelo
rf_model.fit(X_train, y_train)

# Fazendo previs√µes
y_pred_rf = rf_model.predict(X_test)

# Avalia√ß√£o do modelo
mae_rf = mean_absolute_error(y_test, y_pred_rf)
mse_rf= mean_squared_error(y_test, y_pred_rf)
print(f'MAE: {mae_rf:.2f}, MSE: {mse_rf:.2f}')

# Instanciando o modelo
xgb_model = XGBRegressor(random_state=42)

# Treinando o modelo
xgb_model.fit(X_train, y_train)

# Fazendo previs√µes
y_pred_xgb = xgb_model.predict(X_test)

# Avalia√ß√£o do modelo
mae_xgb = mean_absolute_error(y_test, y_pred_xgb)
mse_xgb = mean_squared_error(y_test, y_pred_xgb)
print(f'XGBoost Regressor - MAE: {mae_xgb:.2f}, MSE: {mse_xgb:.2f}')


# Instanciando o modelo
linear_model = LinearRegression()

# Treinando o modelo
linear_model.fit(X_train, y_train)

# Fazendo previs√µes
y_pred_lr = linear_model.predict(X_test)

# Avalia√ß√£o do modelo
mae_linear = mean_absolute_error(y_test, y_pred_lr)
mse_linear = mean_squared_error(y_test, y_pred_lr)
print(f'Regress√£o Linear - MAE: {mae_linear: .2f}, MSE: {mse_linear: .2f}')


# Instanciando o modelo
gbr_model = GradientBoostingRegressor(random_state=42)

# Treinando o modelo
gbr_model.fit(X_train, y_train)

# Fazendo previs√µes
y_pred_gbr = gbr_model.predict(X_test)

# Avalia√ß√£o do modelo
mae_gbr = mean_absolute_error(y_test, y_pred_gbr)
mse_gbr = mean_squared_error(y_test, y_pred_gbr)
print(f'Gradient Boosting Regressor - MAE: {mae_gbr:.2f}, MSE: {mse_gbr:.2f}')

#Compara√ß√£o de MAE e MSE entre Modelos


# Definindo os valores de MAE e MSE para cada modelo
model_names = ['Random Forest', 'Linear Regression', 'XGBoost Regressor', 'Gradient Boosting']
mae_values = [mae_rf, mae_linear, mae_xgb, mae_gbr]
mse_values = [mse_rf, mse_linear, mse_xgb, mse_gbr]

# Criando DataFrame para as m√©tricas
metrics_df = pd.DataFrame({
    'Model': model_names,
    'MAE': mae_values,
    'MSE': mse_values
})

# Gr√°fico de MAE
fig_mae = go.Figure()
fig_mae.add_trace(go.Bar(x=metrics_df['Model'], y=metrics_df['MAE'],
                         name='MAE',
                         marker_color='royalblue'))

fig_mae.update_layout(title='Compara√ß√£o de MAE entre Modelos',
                      xaxis_title='Modelos',
                      yaxis_title='MAE')

# Gr√°fico de MSE
fig_mse = go.Figure()
fig_mse.add_trace(go.Bar(x=metrics_df['Model'], y=metrics_df['MSE'],
                         name='MSE',
                         marker_color='royalblue'))

fig_mse.update_layout(title='Compara√ß√£o de MSE entre Modelos',
                      xaxis_title='Modelos',
                      yaxis_title='MSE')

# Exibindo os gr√°ficos no Streamlit
st.plotly_chart(fig_mae)
st.plotly_chart(fig_mse)

st.markdown('''##### Conclus√£o do melhor modelo:

##### Interpreta√ß√£o dos Resultados
+ Random Forest: Apresentou os menores valores de MAE e MSE, indicando que √© o modelo mais preciso entre os testados.
+ Regress√£o Linear: Teve os maiores valores de MAE e MSE, sugerindo que √© o modelo menos preciso.
+ XGBoost Regressor e Gradient Boosting Regressor: Apresentaram resultados intermedi√°rios, com o Gradient Boosting sendo mais preciso que o XGBoost.


##### An√°lise dos Resultados

> MAE (Mean Absolute Error):

+ O MAE da Regress√£o Linear (99.960,98) √© muito maior do que o da Random Forest (3.738,32). Isso indica que a Random Forest tem um desempenho significativamente melhor em termos de erro absoluto m√©dio.


>MSE (Mean Squared Error):

+ O MSE da Regress√£o Linear (19.166.618.609,47) tamb√©m √© muito superior ao da Random Forest (40.743.711,66), mostrando que a Regress√£o Linear possui um erro quadr√°tico m√©dio bem maior, o que sugere que ela tem mais dificuldades em prever com precis√£o os valores extremos.


''')





# Compara√ß√£o das Vendas Reais e Previstas

# Lista de previs√µes de cada modelo
model_predictions = {
    'Random Forest': y_pred_rf,
    'Regress√£o Linear': y_pred_lr,
    'XGBoost Regressor': y_pred_xgb,
    'Gradient Boosting Regressor': y_pred_gbr
}

# Criando a figura e os eixos para os 4 gr√°ficos (2x2 layout)
fig_comp = sp.make_subplots(rows=2, cols=2, subplot_titles=list(model_predictions.keys()))

for idx, (model_name, y_pred) in enumerate(model_predictions.items()):
    row = idx // 2 + 1
    col = idx % 2 + 1
    fig_comp.add_trace(go.Scatter(x=y_test, y=y_pred, mode='markers', name='Previs√µes'),
                       row=row, col=col)
    fig_comp.add_trace(go.Scatter(x=[min(y_test), max(y_test)], y=[min(y_test), max(y_test)], mode='lines',
                                  name='Linha de Refer√™ncia', line=dict(color='black', dash='dash')),
                       row=row, col=col)
    fig_comp.update_xaxes(title_text='Vendas Reais', row=row, col=col)
    fig_comp.update_yaxes(title_text='Vendas Previstas', row=row, col=col)
    fig_comp.update_layout(title_text=f'Compara√ß√£o das Vendas Reais e Previstas - {model_name}')

fig_comp.update_layout(height=800, width=800, title_text='Compara√ß√£o das Vendas Reais e Previstas por Modelo')

# Exibindo os gr√°ficos no Streamlit
st.plotly_chart(fig_comp)


##  Execute o seguinte codigo no terminal para abrir o app: streamlit run app.py
